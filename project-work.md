Название проектной работы:
Инфраструктура и MLOps пайплайн для Telegram бота «Напоминалка» с использованием LLM, Airflow, Terraform, Docker и Yandex Cloud
План проектной работы
1. Описание проекта
•	Краткое описание Telegram бота «Напоминалка»: принимает текстовые запросы, извлекает время и текст напоминания, сохраняет в БД и отправляет уведомления.
•	Использование LLM модели для:
o	парсинга естественного языка,
o	исправления ошибок,
o	нормализации времени.
•	Обоснование выбора технологий:
o	LLM — улучшение качества понимания запросов.
o	Airflow — автоматизация ETL, обучения и мониторинга модели.
o	Terraform — развёртывание инфраструктуры в Yandex Cloud.
o	Docker Compose — локальный и продакшен деплой.
o	GitHub Actions — CI/CD.
•	Требование: возможность обучения локально и в Yandex Cloud.
2. Структура репозитория
•	/bot — исходный код Telegram бота.
•	/ml — подготовка данных, обучение модели, инференс сервис.
•	/airflow — DAG’и для ETL, обучения и мониторинга.
•	/terraform — конфигурации для Yandex Cloud.
•	/docker — Dockerfile для бота и модели.
•	/.github/workflows — CI/CD пайплайны.
3. CI процессы (GitHub Actions)
•	Триггер сборки при коммите в любую ветку.
•	Проверка качества кода:
o	линтеры (flake8/black),
o	статический анализ (mypy),
o	тесты (pytest).
•	Сборка Docker образов:
o	образ бота,
o	образ модели.
•	Публикация образов в Docker Hub / Yandex Container Registry.
4. Инфраструктура как код (Terraform)
4.1. Конфигурации Terraform
•	Создание ресурсов в Yandex Cloud:
o	виртуальная машина для прод бота,
o	Object Storage для датасетов и моделей,
o	Airflow (Managed Service),
o	DataProc (Spark кластер),
o	сети, роли, сервисные аккаунты.
4.2. Backend для хранения состояния
•	GitHub не хранит Terraform state, поэтому используется:
o	Yandex Object Storage (S3 backend) для облачного окружения,
o	локальный backend для локального обучения.
4.3. Проверки
•	terraform fmt
•	terraform validate
•	terraform plan (в CI)
5. CD процессы
•	Ручной запуск Terraform через GitHub Actions (workflow_dispatch).
•	Развёртывание инфраструктуры в Yandex Cloud.
•	Деплой Docker контейнеров на VPS:
o	обновление docker-compose.yml,
o	перезапуск сервисов (бот, модель, postgres).
•	Проверка работоспособности:
o	доступность API модели,
o	корректность ответа бота,
o	подключение к БД.
6. MLOps пайплайн
6.1. Подготовка данных
•	Исторические запросы пользователей.
•	Генерация синтетических данных через LLM.
•	Airflow DAG: очистка, нормализация, подготовка датасета.
6.2. Обучение модели
•	Возможность обучения:
o	локально (Docker + CPU/GPU),
o	в Yandex Cloud (Spark + DataProc).
•	Airflow DAG: обучение, сохранение артефактов, упаковка модели в Docker образ.
6.3. Деплой модели
•	Публикация образа в registry.
•	Автоматическое обновление сервиса модели на VPS.
6.4. Мониторинг модели
•	Airflow DAG: анализ свежих запросов.
•	Проверка дрейфа данных (Evidently AI).
•	Уведомление о деградации и триггер переобучения.
7. Уничтожение инфраструктуры
•	Отдельный workflow infra-destroy.
•	Выполнение terraform destroy.
•	Проверка, что ресурсы удалены:
o	Airflow,
o	DataProc,
o	Object Storage,
o	сети и сервисные аккаунты.
8. Документация и выводы
•	Описание всех этапов проекта.
•	Архитектурная схема:
o	CI/CD,
o	MLOps пайплайн,
o	инфраструктура.
•	Проблемы и способы решения:
o	настройка backend,
o	работа с Airflow,
o	оптимизация Docker образов.
•	Итоговые выводы о качестве модели и стабильности пайплайна.

