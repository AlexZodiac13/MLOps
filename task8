Нагрузка на систему
Системный администратор сообщил вам, что в среднем, поток событий составляет около 50 транзакций в секунду, однако, перед праздниками это число может достигать 400.

Перед внедрением вам необходимо протестировать работу модели и понять сколько экземпляров модели вам понадобиться поднять для обеспечения требуемого уровня быстродействия.

Облачная среда
Систему MLflow желательно запустить в облачной среде, обеспечив сохранение артефактов в облачном S3 хранилище.

Задания
Решение будет ожидаться в виде репозитория/ветки на GitHub, с terraform конфигурациями и другим необходимым кодом для запуска всей системы.

Обязательные задания
Запустить систему Apache Kafka в сервисе Yandex Cloud Managed Service for Apache Kafka, либо на отдельной виртуальной машине.

Запустить систему Apache Airflow в сервисе Yandex Cloud Managed Service for Apache Airflow, либо на отдельной виртуальной машине.

Создать Python скрипт, который генерирует данные из ретроспективных файлов и записывает их в Apache Kafka.

Создать Spark job, который на потоке применяет модель к данным из Apache Kafka и записывает результаты в другой topic.

Запустить систему MLflow на отдельной виртуальной машине, а также базу данных метаданных для MLflow в сервисе Yandex Cloud Managed Service for PostgreSQL/MySQL либо на отдельной виртуальной машине. Будем забирать лучшую обученную модель из MLflow Model Registry по тегу (например @champion, но можно использовать любой). Для обучения модели можно использовать те же DAG's, что и в предыдущих ДЗ.

Видоизменить DAG для автоматизированного создания и удаления Spark-кластера, запуска скрипта и оценки качества модели и ее быстродействия.

Оценить при какой интенсивности событий (транзакций в секунду) начинает расти очередь необработанных сообщений в Apache Kafka.